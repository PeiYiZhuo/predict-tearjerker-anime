{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a94c2286",
   "metadata": {},
   "source": [
    "# Predicting Tearjerker Anime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0797fa3",
   "metadata": {},
   "source": [
    "One of the few pieces of media to have ever coaxed tears from me is Kyoto Animation's devastating 2008 anime series *Clannad: After Story*. Despite its potential for crushing your soul, the show gets an enthusiatic recommend from me nonetheless. If anything, I consider an anime's ability to turn on the waterworks to be an indicator of its quality. Even if I don't tear up at an anime, a decent attempt on the part of its creators still gets credit from me. Most of my favorite anime are considered tearjerkers, *A Place Further than the Universe*, *Your Name*, and *K-On* come to mind as notable examples. Given my particular afinity for tearjerker anime, wouldn't it be great if I could somehow predict before a show even airs whether it will trigger this particular emotional reaction from the audience? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09bf65a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "# https://pub.towardsai.net/emoticon-and-emoji-in-text-mining-7392c49f596a\n",
    "# https://medium.com/geekculture/text-preprocessing-how-to-handle-emoji-emoticon-641bbfa6e9e7\n",
    "from emot.emo_unicode import EMOTICONS_EMO, EMOJI_UNICODE \n",
    "import pandas as pd\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd399243",
   "metadata": {},
   "source": [
    "# Wrangle Anime Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0a4a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "# https://www.kaggle.com/datasets/marlesson/myanimelist-dataset-animes-profiles-reviews?select=animes.csv\n",
    "animes = pd.read_csv(\"data/animes.csv\") \n",
    "# https://www.kaggle.com/datasets/azathoth42/myanimelist?select=AnimeList.csv\n",
    "AnimeList = pd.read_csv(\"data/AnimeList.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa86bccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "AnimeList = AnimeList[[\"anime_id\", \"title_english\", \"title_synonyms\", \"type\", \"source\", \"producer\", \"licensor\", \"studio\"]]\n",
    "animes = animes.merge(AnimeList, how = \"left\", left_on = \"uid\", right_on = \"anime_id\")\n",
    "anime = animes[[\"uid\", \n",
    "                \"title\", \n",
    "                \"synopsis\", \n",
    "                \"genre\", \n",
    "                \"type\",\n",
    "                \"episodes\", \n",
    "                \"source\", \n",
    "                \"producer\", \n",
    "                \"licensor\", \n",
    "                \"studio\"]]\n",
    "anime = anime.drop_duplicates()\n",
    "anime.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d55bdc",
   "metadata": {},
   "source": [
    "# Construct Target Field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ff2e23",
   "metadata": {},
   "source": [
    "My target field comes from a dataset of anime reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d205eb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews = pd.read_csv(\"data/reviews.csv\")\n",
    "# reviews = reviews.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3335c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "\n",
    "# total_rows = len(reviews)\n",
    "# max_rows = 10000\n",
    "# num_files = math.ceil(total_rows/max_rows)\n",
    "\n",
    "# start = 0\n",
    "# end = 9999\n",
    "\n",
    "# for i in range(1, num_files + 1):\n",
    "#     i = str(i)\n",
    "#     print(\"Writing file #\" + i)\n",
    "#     reviews.iloc[start:(end + 1), :].to_csv(\"data/reviews/reviews\" + i + \".csv\", index = False)\n",
    "#     start += 10000\n",
    "#     end += 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a8840c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating data file #2\n",
      "Concatenating data file #3\n",
      "Concatenating data file #4\n",
      "Concatenating data file #5\n",
      "Concatenating data file #6\n",
      "Concatenating data file #7\n",
      "Concatenating data file #8\n",
      "Concatenating data file #9\n",
      "Concatenating data file #10\n",
      "Concatenating data file #11\n",
      "Concatenating data file #12\n",
      "Concatenating data file #13\n",
      "Concatenating data file #14\n"
     ]
    }
   ],
   "source": [
    "# Read in data\n",
    "reviews = pd.read_csv(\"data/reviews/reviews1.csv\")\n",
    "for i in range(2, 15):\n",
    "    i = str(i)\n",
    "    print(\"Concatenating data file #\" + i)\n",
    "    addition = pd.read_csv(\"data/reviews/reviews\" + i + \".csv\")\n",
    "    reviews = pd.concat([reviews, addition])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57ebabac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only relevant fields\n",
    "reviews = reviews[[\"uid\", \"anime_uid\", \"link\", \"text\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e481d3f7",
   "metadata": {},
   "source": [
    "## Remove front and back matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cba92f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews.reset_index(drop = True)\n",
    "filler = re.compile(r\"^[\\s\\w]*Enjoyment[\\s\\d]*|\\s*Helpful\\s*$\")\n",
    "reviews[\"text\"] = reviews[\"text\"].str.replace(filler, \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea346fe",
   "metadata": {},
   "source": [
    "## Replace emoticons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286e197e",
   "metadata": {},
   "source": [
    "The reviews feature heavy use of emoticons. These symbols allow their users to succintly communicate an emotional reaction through pictograms comprised of punctuation, letters, numbers, etc. Because they convey information on emotion, I want to retain them to help me determine whether an anime is a tearjerker or not. However, since they include punctuation, which will be removed from the text later on in the process of constructing the target field, I opted to replace them with verbal descriptions.\n",
    "\n",
    "I used a dictionary of emoticons from the emo_unicode library . . ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ba493fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://introtopython.org/dictionaries.html#General-Syntax\n",
    "emoticons = {}\n",
    "for symbol, meaning in EMOTICONS_EMO.items():\n",
    "    emoticons[symbol] = \"\".join([word.capitalize() for word in meaning.replace(\",\", \"\").split()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4395ea7",
   "metadata": {},
   "source": [
    ". . . and added a few missing emoticons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57fbb438",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticons[\"(^—^)\"] = \"NormalLaugh\"\n",
    "# https://en.wikipedia.org/wiki/List_of_emoticons\n",
    "emoticons[\">W<\"] = \"Troubled\"\n",
    "emoticons[\"-_-'\"] = \"Troubled\"\n",
    "# https://www.urbandictionary.com/define.php?term=%3E_%3E\n",
    "emoticons[\">_>\"] = \"RightSidewaysLook\"\n",
    "emoticons[\"<_<\"] = \"LeftSidewaysLook\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5788f9a8",
   "metadata": {},
   "source": [
    "Since many long emoticons are simply short ones with additional characters, I sorted the emoticons in descending order according to their length so that, later on, the longer emoticons would be matched prior to shorter emoticons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaecd1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/613183/how-do-i-sort-a-dictionary-by-value\n",
    "# https://www.w3schools.com/python/ref_func_sorted.asp\n",
    "emoticons = dict(sorted(emoticons.items(), key = lambda item: -len(item[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e5895d",
   "metadata": {},
   "source": [
    "I then assembled a list of the emoticons from the dictionary that were used in the reviews. I managed to get , but I'm sure I missed some T_T."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72ca775b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.pythonforbeginners.com/basics/list-comprehensions-in-python\n",
    "# https://www.geeksforgeeks.org/python-accessing-key-value-in-dictionary/\n",
    "# https://stackoverflow.com/questions/4202538/escape-special-characters-in-a-python-string\n",
    "pattern = \"\\s(\" + \"|\".join([re.escape(emoticon) for emoticon in emoticons]) + \")\\W?\"\n",
    "used_emoticons = reviews[\"text\"].str.extractall(pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f32092",
   "metadata": {},
   "source": [
    "Here, I'm converting the dataframe of used emoticons into a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f80c65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.digitalocean.com/community/tutorials/python-convert-numpy-array-to-list\n",
    "used_emoticons = used_emoticons.dropna().drop_duplicates().values.reshape(1, -1)[0].tolist()\n",
    "# https://stackoverflow.com/questions/5352546/extract-subset-of-key-value-pairs-from-dictionary\n",
    "used_emoticons = {symbol: emoticons[symbol] for symbol in used_emoticons}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f858c4b",
   "metadata": {},
   "source": [
    "Again, I'm sorting the emoticons according to their length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d180c89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "used_emoticons = dict(sorted(used_emoticons.items(), key = lambda item: -len(item[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6a26df",
   "metadata": {},
   "source": [
    "Now, I'm looping through each emoticon and replacing it with its respective value in the dictionary if it's preceded by a white space and followed by a non-word character. These conditions are to reduce the likelihood of false-positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aef79d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing m(_ _)m with KowtowAsASignOfRespectOrDogezaForApology\n",
      "Replacing (^_^)/ with Joyful\n",
      "Replacing >^_^< with NormalLaugh\n",
      "Replacing (^_^) with NormalLaugh\n",
      "Replacing (^o^) with Happy\n",
      "Replacing (-_-) with Shame\n",
      "Replacing (._.) with LookingDown\n",
      "Replacing (ToT) with SadOrCrying\n",
      "Replacing (^.^) with NormalLaugh\n",
      "Replacing (*_*) with Amazed\n",
      "Replacing (-.-) with Shame\n",
      "Replacing (=_=) with Tired\n",
      "Replacing -_-' with Troubled\n",
      "Replacing :))) with VeryVeryHappyFaceOrSmiley\n",
      "Replacing (^^) with NormalLaugh\n",
      "Replacing :-)) with VeryHappy\n",
      "Replacing (;_; with SadOfCrying\n",
      "Replacing :)) with VeryHappyFaceOrSmiley\n",
      "Replacing ^_^ with Joyful\n",
      "Replacing ;_; with SadOrCrying\n",
      "Replacing >:) with EvilOrDevilish\n",
      "Replacing T.T with SadOrCrying\n",
      "Replacing :-) with HappyFaceSmiley\n",
      "Replacing :'( with Crying\n",
      "Replacing >W< with Troubled\n",
      "Replacing >_> with RightSidewaysLook\n",
      "Replacing ;-; with SadOrCrying\n",
      "Replacing :') with TearsOfHappiness\n",
      "Replacing >:( with FrownSadAndryOrPouting\n",
      "Replacing :^) with HappyFaceSmiley\n",
      "Replacing o_0 with Surprised\n",
      "Replacing o.O with Surpised\n",
      "Replacing Q.Q with SadOrCrying\n",
      "Replacing >:/ with SkepticalAnnoyedUndecidedUneasyOrHesitant\n",
      "Replacing :-( with FrownSadAndryOrPouting\n",
      "Replacing ;^) with WinkOrSmirk\n",
      "Replacing :-] with HappyFaceOrSmiley\n",
      "Replacing >:O with Yawn\n",
      "Replacing >:P with TongueStickingOutCheekyPlayfulOrBlowingARaspberry\n",
      "Replacing :-} with HappyFaceSmiley\n",
      "Replacing :o) with HappyFaceSmiley\n",
      "Replacing :c) with HappyFaceSmiley\n",
      "Replacing Q_Q with SadOrCrying\n",
      "Replacing 8-) with HappyFaceSmiley\n",
      "Replacing :-3 with HappyFaceSmiley\n",
      "Replacing 0:3 with AngelSaintOrInnocent\n",
      "Replacing >:[ with FrownSadAndryOrPouting\n",
      "Replacing <_< with LeftSidewaysLook\n",
      "Replacing :) with HappyFaceOrSmiley\n",
      "Replacing :D with LaughingBigGrinOrLaughWithGlasses\n",
      "Replacing D: with Sadness\n",
      "Replacing :( with FrownSadAndryOrPouting\n",
      "Replacing ;) with WinkOrSmirk\n",
      "Replacing :P with TongueStickingOutCheekyPlayfulOrBlowingARaspberry\n",
      "Replacing :3 with HappyFaceSmiley\n",
      "Replacing :L with SkepticalAnnoyedUndecidedUneasyOrHesitant\n",
      "Replacing XD with LaughingBigGrinOrLaughWithGlasses\n",
      "Replacing :/ with SkepticalAnnoyedUndecidedUneasyOrHesitant\n",
      "Replacing :] with HappyFaceOrSmiley\n",
      "Replacing =) with HappyFaceSmiley\n",
      "Replacing :> with HappyFaceSmiley\n",
      "Replacing :O with Surprise\n",
      "Replacing :} with HappyFaceSmiley\n",
      "Replacing :o with Surprise\n",
      "Replacing :S with SkepticalAnnoyedUndecidedUneasyOrHesitant\n",
      "Replacing ;D with WinkOrSmirk\n",
      "Replacing =/ with SkepticalAnnoyedUndecidedUneasyOrHesitant\n",
      "Replacing =D with LaughingBigGrinOrLaughWithGlasses\n",
      "Replacing XP with TongueStickingOutCheekyPlayfulOrBlowingARaspberry\n",
      "Replacing *) with WinkOrSmirk\n",
      "Replacing =] with HappyFaceSmiley\n",
      "Replacing ;] with WinkOrSmirk\n",
      "Replacing DX with GreatDismay\n",
      "Replacing D; with GreatDismay\n",
      "Replacing =3 with LaughingBigGrinOrLaughWithGlasses\n",
      "Replacing :X with Kiss\n",
      "Replacing :[ with FrownSadAndryOrPouting\n",
      "Replacing :b with TongueStickingOutCheekyPlayfulOrBlowingARaspberry\n",
      "Replacing :| with StraightFace\n",
      "Replacing 8D with LaughingBigGrinOrLaughWithGlasses\n",
      "Replacing :c with FrownSadAndryOrPouting\n",
      "Replacing :& with SealedLipsOrWearingBracesOrTongue-tied\n",
      "Replacing =p with TongueStickingOutCheekyPlayfulOrBlowingARaspberry\n",
      "Replacing :* with Kiss\n",
      "Replacing ;; with SadOrCrying\n",
      "Replacing :x with SealedLipsOrWearingBracesOrTongue-tied\n",
      "Replacing :< with FrownSadAndryOrPouting\n",
      "Replacing :# with SealedLipsOrWearingBracesOrTongue-tied\n",
      "Replacing :$ with EmbarrassedOrBlushing\n",
      "Replacing %) with DrunkOrConfused\n",
      "Replacing D= with GreatDismay\n",
      "Replacing :@ with FrownSadAndryOrPouting\n",
      "Replacing QQ with SadOrCrying\n",
      "Replacing d: with TongueStickingOutCheekyPlayfulOrBlowingARaspberry\n",
      "Replacing D8 with GreatDismay\n",
      "Replacing oO with Surprised\n"
     ]
    }
   ],
   "source": [
    "for symbol, meaning in used_emoticons.items():\n",
    "    print(\"Replacing \" + symbol + \" with \" + meaning)\n",
    "    reviews[\"text\"] = reviews[\"text\"].str.replace(\"(?<=\\s)\" + re.escape(symbol) + \"(?=\\W?)\", meaning, regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5728e5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.to_csv(\"data/intermediates/replace_emoticons.csv\", index = False)\n",
    "reviews = pd.read_csv(\"data/intermediates/replace_emoticons.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5531148e",
   "metadata": {},
   "source": [
    "## Replace emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0390179e",
   "metadata": {},
   "outputs": [],
   "source": [
    "emojis = {}\n",
    "for meaning, symbol in EMOJI_UNICODE.items():\n",
    "    emojis[symbol] = \"_\".join(meaning.lower().replace(\",\", \"\").replace(\":\", \"\").split())\n",
    "emojis['❤️'] = \"heart\"\n",
    "emojis['♥️'] = \"heart\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13cb113",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"(\" + \"|\".join([re.escape(emoji) for emoji in emojis]) + \")\"\n",
    "used_emojis = reviews[\"text\"].str.extractall(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5f6252",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[\"text\"].iloc[[19803]].str.contains('☺')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d57ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reviews[\"link\"].iloc[19803])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b9cfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "used_emojis = used_emojis.dropna().drop_duplicates().values.reshape(1, -1)[0].tolist()\n",
    "# used_emojis = {symbol: emojis[symbol] for symbol in used_emojis}\n",
    "# for symbol, meaning in used_emojis.items():\n",
    "#     print(\"Replacing \" + symbol + \" with \" + meaning)\n",
    "#     reviews[\"text\"] = reviews[\"text\"].str.replace(symbol, \" \" + meaning + \" \", regex = False)\n",
    "used_emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da981203",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a263ea12",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_characters = reviews[\"text\"].str.extract(r\"(?P<final_character>.$)\", expand = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332a1c17",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None)\n",
    "final_characters = reviews[\"text\"].str.extract(r\"(?P<final_character>.$)\")\n",
    "counts = final_characters.groupby(\"final_character\")[\"final_character\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb8ae49",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(counts.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334ce3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[\"text\"][final_characters['final_character'] == '️']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4635530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts[counts.index == '️']\n",
    "# '⠀', '️', '̿'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b58543",
   "metadata": {},
   "source": [
    "## Tokenize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84cc0b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[\"text\"] = reviews[\"text\"].str.strip()\n",
    "reviews[\"text\"] = reviews[\"text\"].str.lower()\n",
    "reviews[\"text\"] = reviews[\"text\"].str.replace(\"\\\\\", \" \", regex = True)\n",
    "reviews[\"text\"] = reviews[\"text\"].str.replace(\"/\", \" \")                                      \n",
    "reviews[\"text\"] = reviews[\"text\"].str.replace(\"‘\", \"'\").str.replace(\"’\", \"'\")\n",
    "reviews[\"text\"] = reviews[\"text\"].str.replace(\"“\", '\"').str.replace(\"”\", '\"')\n",
    "pattern = \"[\" + string.punctuation.replace(\"'\", \"\").replace(\"-\", \"\") + \"–\" + \"…\" + \"]\" \n",
    "pattern = pattern + r\"|(?<=\\s)'(?=\\w)|(?<=\\w)'(?=\\s)\"\n",
    "reviews[\"text\"] = reviews[\"text\"].str.replace(pattern, \"\", regex = True)\n",
    "reviews[\"text\"] = reviews[\"text\"].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fafef88",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews.explode(\"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463b5c56",
   "metadata": {},
   "source": [
    "## Replace non-word characters except for emojis and select punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124d192d",
   "metadata": {},
   "source": [
    "I will drop all non-word characters that aren't emojis. First, I create a list of the unique non-word characters present in the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41c24573",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tokens = reviews[\"text\"].drop_duplicates()\n",
    "non_word = unique_tokens.str.extractall(r\"(\\W)\").drop_duplicates()\n",
    "non_word = non_word.values.reshape(1, -1)[0].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c887ee1",
   "metadata": {},
   "source": [
    "Next, I reformat the definitions from the emoji dictionary that I obtained from the emot library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98a68511",
   "metadata": {},
   "outputs": [],
   "source": [
    "emojis = {}\n",
    "for meaning, symbol in EMOJI_UNICODE.items():\n",
    "    emojis[symbol] = meaning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a3bf6e",
   "metadata": {},
   "source": [
    "I created a regex pattern that separates all the characters that I want to be dropped by a pipe, `|`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8949ae6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop = [char for char in non_word if char not in emojis]\n",
    "drop.remove(\"'\")\n",
    "drop.remove(\"-\")\n",
    "drop = \"|\".join(drop) # Create regex pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa2aee0",
   "metadata": {},
   "source": [
    "Using the pattern created above, I replaced the non-word characters I specified with empty strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c892d405",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[\"text\"] = reviews[\"text\"].str.replace(drop, \"\", regex = True)\n",
    "reviews = reviews[reviews[\"text\"] != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6850b351",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.to_csv(\"data/intermediates/cleaned_text.csv\", index = False)\n",
    "reviews = pd.read_csv(\"data/intermediates/cleaned_text.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8e6a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews[\"text\"].loc[168].values\n",
    "# reviews[\"text\"].loc[281].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbf0568",
   "metadata": {},
   "source": [
    "## Create target field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5b6208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep = [emoji for emoji in emojis if emoji in non_word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a058db86",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_words = [\"cry\", \n",
    "             \"cried\", \n",
    "             \"crying\", \n",
    "             \"sob\", \n",
    "             \"sobbed\", \n",
    "             \"sobbing\", \n",
    "             \"bawl\", \n",
    "             \"bawled\", \n",
    "             \"bawling\", \n",
    "             \"tear\", \n",
    "             \"tears\", \n",
    "             \"teared\", \n",
    "             \"tearing\", # as in \"tearing up\"\n",
    "             \"sadorcrying\",\n",
    "             \"tearsofhappiness\",\n",
    "             \"sadofcrying\",\n",
    "             \"😭\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8af6731f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[\"cry\"] = reviews[\"text\"].isin(key_words)\n",
    "cry_prop = reviews.groupby(\"anime_uid\")[\"cry\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c1fbcbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cry_prop.to_csv(\"data/intermediates/target_field.csv\")\n",
    "cry_prop = pd.read_csv(\"data/intermediates/target_field.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
