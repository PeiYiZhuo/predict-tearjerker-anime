{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a94c2286",
   "metadata": {},
   "source": [
    "# Predicting Tearjerker Anime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0797fa3",
   "metadata": {},
   "source": [
    "One of the few pieces of media to have ever coaxed tears from me is Kyoto Animation's devastating 2008 anime series *Clannad: After Story*. Despite its potential for crushing your soul, the show gets an enthusiatic recommend from me nonetheless. If anything, I consider an anime's ability to turn on the waterworks to be an indicator of its quality. Even if I don't tear up at an anime, a decent attempt on the part of its creators still gets credit from me. Most of my favorite anime are considered tearjerkers, *A Place Further than the Universe*, *Your Name*, and *K-On* come to mind as notable examples. Given my particular afinity for tearjerker anime, wouldn't it be great if I could somehow predict before a show even airs whether it will trigger this particular emotional reaction from the audience? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bf65a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "# https://pub.towardsai.net/emoticon-and-emoji-in-text-mining-7392c49f596a\n",
    "# https://medium.com/geekculture/text-preprocessing-how-to-handle-emoji-emoticon-641bbfa6e9e7\n",
    "from emot.emo_unicode import EMOTICONS_EMO, EMOJI_UNICODE \n",
    "import pandas as pd\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd399243",
   "metadata": {},
   "source": [
    "# Wrangle Anime Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0a4a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "# https://www.kaggle.com/datasets/marlesson/myanimelist-dataset-animes-profiles-reviews?select=animes.csv\n",
    "animes = pd.read_csv(\"data/animes.csv\") \n",
    "# https://www.kaggle.com/datasets/azathoth42/myanimelist?select=AnimeList.csv\n",
    "AnimeList = pd.read_csv(\"data/AnimeList.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa86bccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "AnimeList = AnimeList[[\"anime_id\", \"title_english\", \"title_synonyms\", \"type\", \"source\", \"producer\", \"licensor\", \"studio\"]]\n",
    "animes = animes.merge(AnimeList, how = \"left\", left_on = \"uid\", right_on = \"anime_id\")\n",
    "anime = animes[[\"uid\", \n",
    "                \"title\", \n",
    "                \"synopsis\", \n",
    "                \"genre\", \n",
    "                \"type\",\n",
    "                \"episodes\", \n",
    "                \"source\", \n",
    "                \"producer\", \n",
    "                \"licensor\", \n",
    "                \"studio\"]]\n",
    "anime = anime.drop_duplicates()\n",
    "anime.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d55bdc",
   "metadata": {},
   "source": [
    "# Construct Target Field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ff2e23",
   "metadata": {},
   "source": [
    "My target field comes from a dataset of anime reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d205eb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews = pd.read_csv(\"data/reviews.csv\")\n",
    "# reviews = reviews.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3335c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "\n",
    "# total_rows = len(reviews)\n",
    "# max_rows = 10000\n",
    "# num_files = math.ceil(total_rows/max_rows)\n",
    "\n",
    "# start = 0\n",
    "# end = 9999\n",
    "\n",
    "# for i in range(1, num_files + 1):\n",
    "#     i = str(i)\n",
    "#     print(\"Writing file #\" + i)\n",
    "#     reviews.iloc[start:(end + 1), :].to_csv(\"data/reviews/reviews\" + i + \".csv\", index = False)\n",
    "#     start += 10000\n",
    "#     end += 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8840c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "reviews = pd.read_csv(\"data/reviews/reviews1.csv\")\n",
    "for i in range(2, 15):\n",
    "    i = str(i)\n",
    "    print(\"Concatenating data file #\" + i)\n",
    "    addition = pd.read_csv(\"data/reviews/reviews\" + i + \".csv\")\n",
    "    reviews = pd.concat([reviews, addition])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ebabac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only relevant fields\n",
    "reviews = reviews[[\"uid\", \"anime_uid\", \"link\", \"text\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e481d3f7",
   "metadata": {},
   "source": [
    "## Remove front and back matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba92f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews.reset_index(drop = True)\n",
    "filler = re.compile(r\"^[\\s\\w]*Enjoyment[\\s\\d]*|\\s*Helpful\\s*$\")\n",
    "reviews[\"text\"] = reviews[\"text\"].str.replace(filler, \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea346fe",
   "metadata": {},
   "source": [
    "## Replace emoticons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286e197e",
   "metadata": {},
   "source": [
    "The reviews feature heavy use of emoticons. These symbols allow their users to succintly communicate an emotional reaction through pictograms comprised of punctuation, letters, numbers, etc. Because they convey information on emotion, I want to retain them to help me determine whether an anime is a tearjerker or not. However, since they include punctuation, which will be removed from the text later on in the process of constructing the target field, I opted to replace them with verbal descriptions.\n",
    "\n",
    "I used a dictionary of emoticons from the emo_unicode library . . ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba493fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://introtopython.org/dictionaries.html#General-Syntax\n",
    "emoticons = {}\n",
    "for symbol, meaning in EMOTICONS_EMO.items():\n",
    "    emoticons[symbol] = \"_\".join(meaning.lower().replace(\",\", \"\").split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4395ea7",
   "metadata": {},
   "source": [
    ". . . and added a few missing emoticons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fbb438",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticons[\"(^‚Äî^)\"] = \"normal_laugh\"\n",
    "# https://en.wikipedia.org/wiki/List_of_emoticons\n",
    "emoticons[\">W<\"] = \"troubled\"\n",
    "emoticons[\"-_-'\"] = \"troubled\"\n",
    "# https://www.urbandictionary.com/define.php?term=%3E_%3E\n",
    "emoticons[\">_>\"] = \"right_sideways_look\"\n",
    "emoticons[\"<_<\"] = \"left_sideways_look\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5788f9a8",
   "metadata": {},
   "source": [
    "Since many long emoticons are simply short ones with additional characters, I sorted the emoticons in descending order according to their length so that, later on, the longer emoticons would be matched prior to shorter emoticons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaecd1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/613183/how-do-i-sort-a-dictionary-by-value\n",
    "# https://www.w3schools.com/python/ref_func_sorted.asp\n",
    "emoticons = dict(sorted(emoticons.items(), key = lambda item: -len(item[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e5895d",
   "metadata": {},
   "source": [
    "I then assembled a list of the emoticons from the dictionary that were used in the reviews. I managed to get , but I'm sure I missed some T_T."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ca775b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.pythonforbeginners.com/basics/list-comprehensions-in-python\n",
    "# https://www.geeksforgeeks.org/python-accessing-key-value-in-dictionary/\n",
    "# https://stackoverflow.com/questions/4202538/escape-special-characters-in-a-python-string\n",
    "pattern = \"\\s(\" + \"|\".join([re.escape(emoticon) for emoticon in emoticons]) + \")\\W?\"\n",
    "used_emoticons = reviews[\"text\"].str.extractall(pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f32092",
   "metadata": {},
   "source": [
    "Here, I'm converting the dataframe of used emoticons into a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f80c65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.digitalocean.com/community/tutorials/python-convert-numpy-array-to-list\n",
    "used_emoticons = used_emoticons.dropna().drop_duplicates().values.reshape(1, -1)[0].tolist()\n",
    "# https://stackoverflow.com/questions/5352546/extract-subset-of-key-value-pairs-from-dictionary\n",
    "used_emoticons = {symbol: emoticons[symbol] for symbol in used_emoticons}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f858c4b",
   "metadata": {},
   "source": [
    "Again, I'm sorting the emoticons according to their length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d180c89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "used_emoticons = dict(sorted(used_emoticons.items(), key = lambda item: -len(item[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6a26df",
   "metadata": {},
   "source": [
    "Now, I'm looping through each emoticon and replacing it with its respective value in the dictionary if it's preceded by a white space and followed by a non-word character. These conditions are to reduce the likelihood of false-positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef79d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "for symbol, meaning in used_emoticons.items():\n",
    "    print(\"Replacing \" + symbol + \" with \" + meaning)\n",
    "    reviews[\"text\"] = reviews[\"text\"].str.replace(\"(?<=\\s)\" + re.escape(symbol) + \"(?=\\W?)\", meaning, regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5728e5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews.to_csv(\"data/intermediates/replace_emoticons.csv\", index = False)\n",
    "reviews = pd.read_csv(\"data/intermediates/replace_emoticons.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5531148e",
   "metadata": {},
   "source": [
    "## Replace emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0390179e",
   "metadata": {},
   "outputs": [],
   "source": [
    "emojis = {}\n",
    "for meaning, symbol in EMOJI_UNICODE.items():\n",
    "    emojis[symbol] = \"_\".join(meaning.lower().replace(\",\", \"\").replace(\":\", \"\").split())\n",
    "emojis['‚ù§Ô∏è'] = \"heart\"\n",
    "emojis['‚ô•Ô∏è'] = \"heart\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13cb113",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"(\" + \"|\".join([re.escape(emoji) for emoji in emojis]) + \")\"\n",
    "used_emojis = reviews[\"text\"].str.extractall(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5f6252",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[\"text\"].iloc[[19803]].str.contains('‚ò∫')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d57ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reviews[\"link\"].iloc[19803])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b9cfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "used_emojis = used_emojis.dropna().drop_duplicates().values.reshape(1, -1)[0].tolist()\n",
    "# used_emojis = {symbol: emojis[symbol] for symbol in used_emojis}\n",
    "# for symbol, meaning in used_emojis.items():\n",
    "#     print(\"Replacing \" + symbol + \" with \" + meaning)\n",
    "#     reviews[\"text\"] = reviews[\"text\"].str.replace(symbol, \" \" + meaning + \" \", regex = False)\n",
    "used_emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da981203",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a263ea12",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_characters = reviews[\"text\"].str.extract(r\"(?P<final_character>.$)\", expand = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332a1c17",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None)\n",
    "final_characters = reviews[\"text\"].str.extract(r\"(?P<final_character>.$)\")\n",
    "counts = final_characters.groupby(\"final_character\")[\"final_character\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb8ae49",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(counts.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334ce3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[\"text\"][final_characters['final_character'] == 'Ô∏è']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4635530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts[counts.index == 'Ô∏è']\n",
    "# '‚†Ä', 'Ô∏è', 'Ãø'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b58543",
   "metadata": {},
   "source": [
    "## Tokenize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cc0b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[\"text\"] = reviews[\"text\"].str.strip()\n",
    "reviews[\"text\"] = reviews[\"text\"].str.lower()\n",
    "reviews[\"text\"] = reviews[\"text\"].str.replace(\"\\\\\", \" \", regex = True)\n",
    "reviews[\"text\"] = reviews[\"text\"].str.replace(\"/\", \" \")                                      \n",
    "reviews[\"text\"] = reviews[\"text\"].str.replace(\"‚Äò\", \"'\").str.replace(\"‚Äô\", \"'\")\n",
    "reviews[\"text\"] = reviews[\"text\"].str.replace(\"‚Äú\", '\"').str.replace(\"‚Äù\", '\"')\n",
    "pattern = \"[\" + string.punctuation.replace(\"'\", \"\").replace(\"-\", \"\") + \"‚Äì\" + \"‚Ä¶\" + \"]\" \n",
    "pattern = pattern + r\"|(?<=\\s)'(?=\\w)|(?<=\\w)'(?=\\s)\"\n",
    "reviews[\"text\"] = reviews[\"text\"].str.replace(pattern, \"\", regex = True)\n",
    "reviews[\"text\"] = reviews[\"text\"].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fafef88",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews.explode(\"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89114f77",
   "metadata": {},
   "source": [
    "## Replace non-word characters except for emojis and select punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ff6ca2",
   "metadata": {},
   "source": [
    "First, I create a list of the unique non-word characters present in the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c24573",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tokens = reviews[\"text\"].drop_duplicates()\n",
    "non_word = unique_tokens.str.extractall(r\"(\\W)\").drop_duplicates()\n",
    "non_word = non_word.values.reshape(1, -1)[0].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27528e47",
   "metadata": {},
   "source": [
    "Next, I reformat the definitions from the emoji dictionary that I obtained from ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a68511",
   "metadata": {},
   "outputs": [],
   "source": [
    "emojis = {}\n",
    "for meaning, symbol in EMOJI_UNICODE.items():\n",
    "    emojis[symbol] = \"_\".join(meaning.lower().replace(\",\", \"\").replace(\":\", \"\").split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8949ae6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = [emoji for emoji in emojis if emoji in non_word]\n",
    "drop = [char for char in non_word if char not in emojis]\n",
    "drop.remove(\"'\")\n",
    "drop.remove(\"-\")\n",
    "drop = \"|\".join(drop) # Create regex pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d53157",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[\"text\"] = reviews[\"text\"].str.replace(drop, \"\", regex = True)\n",
    "reviews[reviews[\"text\"] != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e629a7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f34c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews[\"text\"].loc[168].values\n",
    "# reviews[\"text\"].loc[281].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbf0568",
   "metadata": {},
   "source": [
    "## Create target field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a058db86",
   "metadata": {},
   "outputs": [],
   "source": [
    "[\"cry\", \"cried\", \"crying\", \"sob\", \"sobbed\", \"sobbing\", \"bawl\", \"bawled\", \"bawling\", \"tear\", \"tears\", üò≠]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd6246f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cry = reviews[[\"anime_uid\", \"text\"]][reviews[\"tokenized_text\"].apply(lambda x: sum([y == \"cry\" for y in x])) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6caa0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cry2 = cry.groupby(\"anime_uid\")[\"anime_uid\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebf01e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cry2.plot(kind = \"hist\", bins = 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
